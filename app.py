import streamlit as st
import numpy as np
from faster_whisper import WhisperModel
import tempfile
import os
import librosa
import io
import time
import subprocess
import sys
import warnings
warnings.filterwarnings("ignore")

# Configura√ß√£o da p√°gina com carregamento otimizado
st.set_page_config(
    page_title="Transcri√ß√£o de √Åudio - PT-BR",
    page_icon="üéôÔ∏è",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS para melhorar performance
st.markdown("""
<style>
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    .reportview-container {
        background-color: #f0f2f6;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo e descri√ß√£o
st.title("üéôÔ∏è Transcri√ß√£o de √Åudio em Portugu√™s Brasileiro")
st.markdown("""
Fa√ßa upload de um arquivo de √°udio e obtenha a transcri√ß√£o autom√°tica em portugu√™s!
""")

# Fun√ß√£o para verificar se FFmpeg est√° instalado
def check_ffmpeg():
    try:
        subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False

# Verifica FFmpeg
ffmpeg_available = check_ffmpeg()

if not ffmpeg_available:
    with st.sidebar:
        st.warning("‚ö†Ô∏è FFmpeg n√£o encontrado - usando m√©todo alternativo")

# Sidebar com configura√ß√µes
with st.sidebar:
    st.title("Configura√ß√µes")
    
    # Sele√ß√£o do modelo
    model_size = st.selectbox(
        "Tamanho do Modelo:",
        ["tiny", "base", "small", "medium"],
        index=1,
        help="Modelos maiores s√£o mais precisos mas mais lentos"
    )
    
    # Configura√ß√µes de transcri√ß√£o
    beam_size = st.slider("Beam Size", 1, 5, 2)
    best_of = st.slider("Best Of", 1, 5, 2)
    temperature = st.slider("Temperatura", 0.0, 1.0, 0.0, 0.1)
    vad_filter = st.checkbox("Filtro VAD", value=True, help="Detec√ß√£o de atividade de voz")

# Fun√ß√£o para carregar o modelo com fallback
@st.cache_resource(show_spinner=False)
def load_model(model_size):
    try:
        # Limita o uso de mem√≥ria
        import torch
        if torch.cuda.is_available():
            device = "cuda"
            compute_type = "float16"
            # Limita o uso de VRAM
            torch.cuda.set_per_process_memory_fraction(0.8)
        else:
            device = "cpu"
            compute_type = "int8"
        
        # Usa modelos menores se houver limita√ß√£o de mem√≥ria
        if model_size in ["large-v2", "large-v3"] and device == "cpu":
            model_size = "medium"
            st.sidebar.info("Usando modelo medium (large requer muita RAM)")
        
        model = WhisperModel(
            model_size,
            device=device,
            compute_type=compute_type,
            download_root="./models"
        )
        return model
    except Exception as e:
        st.error(f"Erro ao carregar modelo {model_size}: {str(e)}")
        # Tenta carregar modelo menor como fallback
        if model_size != "tiny":
            st.info("Tentando carregar modelo tiny como fallback...")
            try:
                model = WhisperModel(
                    "tiny",
                    device="cpu",
                    compute_type="int8"
                )
                return model
            except:
                pass
        return None

# Fun√ß√£o otimizada para converter √°udio
def convert_audio_optimized(_uploaded_file, progress_callback=None):
    """Converte √°udio de forma otimizada"""
    try:
        if progress_callback:
            progress_callback(10, "üì• Lendo arquivo...")
        
        # L√™ o arquivo diretamente com librosa (mais leve)
        audio_data, original_sr = librosa.load(
            io.BytesIO(_uploaded_file.read()),
            sr=None,
            mono=True
        )
        
        if progress_callback:
            progress_callback(40, "üîß Convertendo amostragem...")
        
        # Converte para 16kHz se necess√°rio
        if original_sr != 16000:
            audio_data = librosa.resample(audio_data, orig_sr=original_sr, target_sr=16000)
        
        if progress_callback:
            progress_callback(70, "üíæ Salvando arquivo...")
        
        # Salva como WAV tempor√°rio
        import soundfile as sf
        temp_path = tempfile.mktemp(suffix=".wav")
        sf.write(temp_path, audio_data, 16000)
        
        if progress_callback:
            progress_callback(100, "‚úÖ Convers√£o conclu√≠da!")
        
        return temp_path
        
    except Exception as e:
        st.error(f"Erro na convers√£o: {str(e)}")
        return None

# Fun√ß√£o otimizada para transcri√ß√£o
def transcribe_audio_optimized(_model, _audio_path, progress_callback=None):
    """Transcreve √°udio de forma otimizada"""
    try:
        if progress_callback:
            progress_callback(0, "üéØ Iniciando transcri√ß√£o...")
        
        segments, info = _model.transcribe(
            _audio_path,
            language="pt",
            beam_size=beam_size,
            best_of=best_of,
            temperature=temperature,
            vad_filter=vad_filter,
            without_timestamps=False
        )
        
        if progress_callback:
            progress_callback(30, "üìù Processando segmentos...")
        
        # Processa segmentos em lotes para evitar memory leak
        transcriptions = []
        batch_size = 10
        current_batch = []
        
        for i, segment in enumerate(segments):
            current_batch.append({
                'start': segment.start,
                'end': segment.end,
                'text': segment.text.strip()
            })
            
            # Atualiza progresso a cada lote
            if i % batch_size == 0 and progress_callback:
                progress = 30 + min(60, (i / 100) * 60)
                progress_callback(progress, f"üìù Processando... {i} segmentos")
        
        transcriptions = current_batch
        
        if progress_callback:
            progress_callback(100, "‚úÖ Transcri√ß√£o conclu√≠da!")
        
        return transcriptions, info
        
    except Exception as e:
        st.error(f"Erro na transcri√ß√£o: {str(e)}")
        return None, None

# Interface principal
uploaded_file = st.file_uploader(
    "Fa√ßa upload do arquivo de √°udio (m√°x. 50MB)",
    type=['wav', 'mp3', 'm4a'],
    help="Formatos suportados: WAV, MP3, M4A. Arquivos menores processam mais r√°pido."
)

# Limita tamanho do arquivo
if uploaded_file and uploaded_file.size > 50 * 1024 * 1024:
    st.error("‚ö†Ô∏è Arquivo muito grande! Por favor, use arquivos menores que 50MB.")
    st.stop()

# Carrega o modelo apenas quando necess√°rio
if uploaded_file is not None:
    with st.spinner("üîÑ Carregando modelo de transcri√ß√£o..."):
        model = load_model(model_size)
    
    if model is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar o modelo de transcri√ß√£o.")
        st.stop()

# Processamento principal
if uploaded_file is not None and model is not None:
    # Informa√ß√µes do arquivo
    st.subheader("üìÑ Informa√ß√µes do Arquivo")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Nome", uploaded_file.name)
    with col2:
        st.metric("Tamanho", f"{uploaded_file.size / 1024 / 1024:.1f} MB")
    
    # Bot√£o de transcri√ß√£o
    if st.button("üéØ Iniciar Transcri√ß√£o", type="primary", use_container_width=True):
        
        # Containers para progresso
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        
        def update_progress(progress, message):
            with progress_placeholder:
                st.progress(progress, text=message)
            status_placeholder.text(message)
        
        try:
            # Fase 1: Convers√£o
            update_progress(0, "üîÑ Iniciando convers√£o de √°udio...")
            audio_path = convert_audio_optimized(uploaded_file, update_progress)
            
            if not audio_path:
                st.error("‚ùå Falha na convers√£o do √°udio")
                st.stop()
            
            # Fase 2: Transcri√ß√£o
            start_time = time.time()
            segments, info = transcribe_audio_optimized(model, audio_path, update_progress)
            end_time = time.time()
            
            # Limpeza
            if os.path.exists(audio_path):
                os.unlink(audio_path)
            
            if not segments:
                st.error("‚ùå Falha na transcri√ß√£o do √°udio")
                st.stop()
            
            # Resultados
            st.success(f"‚úÖ Transcri√ß√£o conclu√≠da em {end_time - start_time:.1f} segundos!")
            
            # Estat√≠sticas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Dura√ß√£o", f"{info.duration:.1f}s")
            with col2:
                st.metric("Idioma", info.language.upper())
            with col3:
                st.metric("Confian√ßa", f"{info.language_probability*100:.0f}%")
            
            # Transcri√ß√£o completa
            st.subheader("üìù Transcri√ß√£o Completa")
            full_text = " ".join(segment['text'] for segment in segments)
            st.text_area("Texto transcrito:", full_text, height=150, key="transcription")
            
            # Segmentos com timestamps
            st.subheader("‚è±Ô∏è Segmentos com Timestamps")
            for i, segment in enumerate(segments[:20]):  # Limita a 20 segmentos para performance
                with st.expander(f"Segmento {i+1} - {segment['start']:.1f}s a {segment['end']:.1f}s"):
                    st.write(segment['text'])
            
            if len(segments) > 20:
                st.info(f"üìã Mostrando os primeiros 20 de {len(segments)} segmentos")
            
            # Download
            st.subheader("üíæ Download")
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    "üì• Baixar TXT",
                    full_text,
                    file_name=f"transcricao_{uploaded_file.name.split('.')[0]}.txt",
                    use_container_width=True
                )
            
            with col2:
                timestamp_text = "\n".join(
                    f"[{s['start']:.1f}s-{s['end']:.1f}s] {s['text']}" 
                    for s in segments
                )
                st.download_button(
                    "‚è±Ô∏è Baixar com Timestamps",
                    timestamp_text,
                    file_name=f"transcricao_timestamps_{uploaded_file.name.split('.')[0]}.txt",
                    use_container_width=True
                )
                
        except Exception as e:
            st.error(f"‚ùå Erro durante o processamento: {str(e)}")
            st.info("üí° Dica: Tente usar um arquivo menor ou modelo tiny")

# Instru√ß√µes
with st.expander("üìñ Instru√ß√µes de Uso"):
    st.markdown("""
    **Como usar:**
    1. Fa√ßa upload de um arquivo de √°udio (at√© 50MB)
    2. Ajuste as configura√ß√µes na sidebar se necess√°rio
    3. Clique em 'Iniciar Transcri√ß√£o'
    4. Aguarde o processamento
    5. Visualize e baixe o resultado

    **Dicas para melhor performance:**
    - Use arquivos WAV quando poss√≠vel
    - Modelos menores (tiny, base) s√£o mais r√°pidos
    - Arquivos curtos (< 10min) processam mais r√°pido
    - Evite m√∫ltiplas transcri√ß√µes simult√¢neas

    **Formatos suportados:** WAV, MP3, M4A
    """)

# Rodap√©
st.markdown("---")
st.markdown(
    "Desenvolvido com Streamlit + Faster-Whisper ‚Ä¢ "
    "[Problemas? Reduza o tamanho do arquivo ou use modelo tiny]"
)

if uploaded_file is None:
    st.info("üëÜ Fa√ßa upload de um arquivo de √°udio para come√ßar!")
